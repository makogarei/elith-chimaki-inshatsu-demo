import re
from pathlib import Path
from typing import List, Optional

import altair as alt
import pandas as pd
import streamlit as st
from openai import OpenAI
from streamlit_markdown import st_markdown

try:
    from weasyprint import HTML  # type: ignore
except Exception:  # pragma: no cover
    HTML = None  # optional dependency for PDFç”Ÿæˆ


st.set_page_config(
    page_title="åƒå·»å°åˆ·ç”£æ¥­æ ªå¼ä¼šç¤¾æ§˜ãƒ‡ãƒ¢",
    page_icon="ğŸ“ˆ",
    layout="wide",
)

BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "datas"
DEFAULT_MODEL = "gpt-5.1"  # gpt-5ç³»ã‚’æŒ‡å®šã™ã‚‹å ´åˆã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ä¸Šæ›¸ãã—ã¦ãã ã•ã„
PRIMARY = "#0ea5e9"
ACCENT = "#f97316"
SURFACE = "#ffffff"
MUTED = "#475569"
DEFAULT_LP_URL = "https://www.elith.ai/"
DEFAULT_REPORT_MODEL = "o3-deep-research-2025-06-26"  # Deep Researchç³»ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š


def inject_styles() -> None:
    st.markdown(
        f"""
        <style>
        :root {{
            --primary: {PRIMARY};
            --accent: {ACCENT};
            --surface: {SURFACE};
            --muted: {MUTED};
        }}
        html, body, [class*="css"] {{
            font-family: 'Noto Sans JP', 'Inter', system-ui, -apple-system, sans-serif;
            background: #f8fafc;
            color: #0f172a;
        }}
        .block-container {{
            padding-top: 56px;
            padding-bottom: 40px;
        }}
        .hero {{
            padding: 24px 26px;
            border-radius: 14px;
            background: linear-gradient(120deg, rgba(14,165,233,0.12), rgba(249,115,22,0.10));
            border: 1px solid rgba(148,163,184,0.25);
            margin-bottom: 20px;
        }}
        .hero-title {{
            font-size: 28px;
            font-weight: 700;
            color: #0f172a;
            margin-bottom: 4px;
        }}
        .hero-sub {{
            color: #334155;
            font-size: 15px;
        }}
        .badge {{
            display: inline-block;
            padding: 4px 10px;
            border-radius: 999px;
            background: rgba(14,165,233,0.12);
            color: #0f172a;
            font-size: 12px;
            margin-right: 6px;
        }}
        .metric-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
            gap: 10px;
            margin: 6px 0 12px 0;
        }}
        .metric-card {{
            padding: 14px;
            border-radius: 12px;
            background: #ffffff;
            border: 1px solid rgba(148,163,184,0.25);
            box-shadow: 0 10px 30px rgba(15,23,42,0.05);
        }}
        .metric-title {{ color: #475569; font-size: 14px; margin-bottom: 6px; letter-spacing: 0.2px; }}
        .metric-value {{ color: #0f172a; font-size: 24px; font-weight: 700; }}
        .metric-desc {{ color: var(--muted); font-size: 12px; }}
        .pill {{
            padding: 4px 10px;
            background: rgba(14,165,233,0.12);
            color: #0f172a;
            border-radius: 999px;
            font-size: 12px;
        }}
        /* Tabs */
        .stTabs [role="tablist"] {{
            gap: 8px;
            border-bottom: 1px solid #e2e8f0;
            padding-bottom: 4px;
        }}
        .stTabs [role="tab"] {{
            padding: 10px 14px;
            border-radius: 10px 10px 0 0;
            background: #e2e8f0;
            color: #475569;
            border: 1px solid transparent;
            font-weight: 600;
        }}
        .stTabs [role="tab"][aria-selected="true"] {{
            background: #e0f2fe;
            color: #0f172a;
            border: 1px solid #bae6fd;
        }}
        /* Expander as panel */
        [data-testid="stExpander"] > details {{
            border: 1px solid #e2e8f0;
            background: #f1f5f9;
            border-radius: 14px;
        }}
        [data-testid="stExpander"] summary {{
            color: #0f172a;
            font-weight: 700;
        }}
        /* Dataframe tweaks */
        [data-testid="stDataFrame"] div[data-testid="stVerticalBlock"] {{
            background: #ffffff;
            border: 1px solid #e2e8f0;
            border-radius: 12px;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )


def get_api_key() -> Optional[str]:
    """secrets.toml ã‹ã‚‰API Keyã‚’å–å¾—ã€‚"""
    return st.secrets.get("openai_api_key") or st.secrets.get("OPENAI_API_KEY")


def parse_int(value: Optional[str]) -> Optional[int]:
    if pd.isna(value):
        return None
    try:
        return int(str(value).replace(",", "").strip())
    except ValueError:
        return None


def parse_percent(value: Optional[str]) -> Optional[float]:
    if pd.isna(value):
        return None
    text = str(value).replace("%", "").replace(",", "").strip()
    try:
        return float(text) / 100.0
    except ValueError:
        return None


def format_seconds(value: Optional[float]) -> str:
    if value is None or pd.isna(value):
        return "â€”"
    minutes, seconds = divmod(int(value), 60)
    return f"{minutes}m {seconds:02d}s"


def markdown_to_html(md_text: str) -> str:
    # ç°¡æ˜“ãªMarkdownâ†’HTMLå¤‰æ›ï¼ˆè¦‹å‡ºã—ã¨ç®‡æ¡æ›¸ãã®ã¿ï¼‰
    lines = md_text.splitlines()
    html_lines = []
    for line in lines:
        if line.startswith("### "):
            html_lines.append(f"<h3>{line[4:].strip()}</h3>")
        elif line.startswith("## "):
            html_lines.append(f"<h2>{line[3:].strip()}</h2>")
        elif line.startswith("# "):
            html_lines.append(f"<h1>{line[2:].strip()}</h1>")
        elif line.startswith("- "):
            # ç°¡æ˜“ãƒªã‚¹ãƒˆ
            if not html_lines or not html_lines[-1].startswith("<ul>"):
                html_lines.append("<ul>")
            html_lines.append(f"<li>{line[2:].strip()}</li>")
        else:
            # ãƒªã‚¹ãƒˆé–‰ã˜
            if html_lines and html_lines[-1].startswith("<li>") and "</ul>" not in html_lines[-1]:
                html_lines.append("</ul>")
            html_lines.append(f"<p>{line}</p>")
    if html_lines and html_lines[-1].startswith("<li>") and "</ul>" not in html_lines[-1]:
        html_lines.append("</ul>")
    return "\n".join(html_lines)


def tune_chart(chart: alt.Chart) -> alt.Chart:
    """Altairå…±é€šã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨ã€‚"""
    return (
        chart.configure_axis(labelFontSize=12, titleFontSize=12, gridColor="#e2e8f0")
        .configure_legend(labelFontSize=12, titleFontSize=12)
        .configure_view(strokeWidth=0)
    )


def html_to_pdf_bytes(html: str) -> Optional[bytes]:
    if HTML is None:
        return None
    return HTML(string=html).write_pdf()


def parse_duration_to_seconds(text: Optional[str]) -> Optional[int]:
    if pd.isna(text):
        return None
    minutes = 0
    seconds = 0
    text = str(text)
    min_match = re.search(r"(\d+)m", text)
    sec_match = re.search(r"(\d+)s", text)
    if min_match:
        minutes = int(min_match.group(1))
    if sec_match:
        seconds = int(sec_match.group(1))
    return minutes * 60 + seconds


def load_csv(uploaded_file, fallback_name: str) -> pd.DataFrame:
    if uploaded_file is not None:
        return pd.read_csv(uploaded_file)
    fallback_path = DATA_DIR / fallback_name
    if fallback_path.exists():
        return pd.read_csv(fallback_path)
    return pd.DataFrame()


def clean_traffic(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    temp = df.copy()
    temp["date"] = pd.to_datetime(temp["æ—¥ä»˜"], errors="coerce")
    temp["pageviews"] = temp["ãƒšãƒ¼ã‚¸é–²è¦§æ•°"].apply(parse_int)
    temp["sessions"] = temp["ã‚µã‚¤ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°"].apply(parse_int)
    temp["unique_visitors"] = temp["ãƒ¦ãƒ‹ãƒ¼ã‚¯è¨ªå•è€…æ•°"].apply(parse_int)
    temp["bounce_rate"] = temp["ä¸é”ç‡"].apply(parse_percent)
    temp["avg_session_seconds"] = temp["å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“"].apply(
        parse_duration_to_seconds
    )
    return temp.dropna(subset=["date"])


def clean_conversion(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    temp = df.copy()
    temp.rename(
        columns={"ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚«ãƒ†ã‚´ãƒªãƒ¼": "traffic_category", "ã‚¢ã‚¯ã‚»ã‚¹å…ƒ": "source"},
        inplace=True,
    )
    temp["sessions"] = temp["ã‚µã‚¤ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³"].apply(parse_int)
    temp["pageviews"] = temp["ãƒšãƒ¼ã‚¸é–²è¦§æ•°"].apply(parse_int)
    temp["unique_visitors"] = temp["ãƒ¦ãƒ‹ãƒ¼ã‚¯è¨ªå•è€…"].apply(parse_int)
    return temp


def clean_clicks(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    temp = df.copy()
    temp.rename(
        columns={
            "ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆ": "button_text",
            "ãƒœã‚¿ãƒ³ã‚¿ã‚¤ãƒ—": "button_type",
            "ãƒšãƒ¼ã‚¸ãƒ‘ã‚¹": "page_path",
            "ãƒªãƒ³ã‚¯å…ˆã‚¢ã‚¤ãƒ†ãƒ ": "link_item",
            "ãƒªãƒ³ã‚¯è©³ç´°": "link_detail",
        },
        inplace=True,
    )
    temp["visitors"] = temp["ãƒ¦ãƒ‹ãƒ¼ã‚¯è¨ªå•è€…æ•°"].apply(parse_int)
    temp["clicks"] = temp["ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¯ãƒªãƒƒã‚¯æ•°"].apply(parse_int)
    temp["click_rate"] = temp["ã‚¯ãƒªãƒƒã‚¯ç‡"].apply(parse_percent)
    return temp


def summarize_traffic(df: pd.DataFrame) -> dict:
    if df.empty:
        return {}
    total_sessions = df["sessions"].sum(skipna=True)
    total_pageviews = df["pageviews"].sum(skipna=True)
    total_visitors = df["unique_visitors"].sum(skipna=True)

    weighted_time = (
        (df["avg_session_seconds"] * df["sessions"]).sum(skipna=True)
        / total_sessions
        if total_sessions
        else None
    )
    weighted_bounce = (
        (df["bounce_rate"] * df["sessions"]).sum(skipna=True) / total_sessions
        if total_sessions
        else None
    )

    return {
        "total_sessions": int(total_sessions) if pd.notna(total_sessions) else None,
        "total_pageviews": int(total_pageviews) if pd.notna(total_pageviews) else None,
        "total_visitors": int(total_visitors) if pd.notna(total_visitors) else None,
        "avg_session_seconds": weighted_time,
        "bounce_rate": weighted_bounce,
    }


def build_page_click_summary(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    grouped = (
        df.groupby("page_path")
        .agg(
            visitors=("visitors", "sum"),
            clicks=("clicks", "sum"),
            avg_click_rate=("click_rate", "mean"),
        )
        .reset_index()
    )
    grouped["click_rate_calc"] = grouped["clicks"] / grouped["visitors"].replace(
        {0: pd.NA}
    )
    return grouped.sort_values("clicks", ascending=False)


def behavioral_highlights(traffic_df: pd.DataFrame, page_click_df: pd.DataFrame) -> List[str]:
    highlights: List[str] = []
    if not traffic_df.empty:
        latest = traffic_df.sort_values("date").tail(3)
        if not latest.empty:
            avg_sessions = latest["sessions"].mean()
            delta = latest["sessions"].pct_change().mean()
            if pd.notna(delta):
                trend = "å¢—åŠ " if delta > 0 else "æ¸›å°‘"
                highlights.append(
                    f"ç›´è¿‘3æ—¥é–“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å¹³å‡ã¯ç´„{avg_sessions:.0f}ã€‚å‰æ—¥æ¯”å¹³å‡ã¯{delta*100:+.1f}%ã§{trend}å‚¾å‘ã€‚"
                )
    if not page_click_df.empty:
        top_pages = page_click_df.head(3)
        names = ", ".join(top_pages["page_path"].tolist())
        highlights.append(f"ã‚¯ãƒªãƒƒã‚¯ãŒå¤šã„ãƒšãƒ¼ã‚¸: {names}")
        low_engagement = (
            page_click_df[
                (page_click_df["click_rate_calc"] < page_click_df["click_rate_calc"].median())
                & (page_click_df["visitors"] > 50)
            ]
            .sort_values("click_rate_calc")
            .head(3)
        )
        if not low_engagement.empty:
            low_list = ", ".join(low_engagement["page_path"].tolist())
            highlights.append(f"ã‚¯ãƒªãƒƒã‚¯ç‡ãŒä½ã‚ã®ãƒšãƒ¼ã‚¸: {low_list}")
    return highlights


def build_ai_prompt(
    summary: dict,
    conversion_df: pd.DataFrame,
    page_click_df: pd.DataFrame,
    extra_context: str = "",
) -> str:
    lines = [
        "ä»¥ä¸‹ã¯LPè¡Œå‹•ãƒ­ã‚°ã®ã‚µãƒãƒªãƒ¼ã§ã™ã€‚LPæ”¹å–„ã®ãŸã‚ã®å…·ä½“çš„ãªææ¡ˆã‚’3ã€œ5ç‚¹ã€æ—¥æœ¬èªã§çŸ­ãç®‡æ¡æ›¸ãã—ã¦ãã ã•ã„ã€‚",
        "",
    ]
    if summary:
        lines.append(
            f"- é›†è¨ˆæœŸé–“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆè¨ˆ: {summary.get('total_sessions')} / ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼åˆè¨ˆ: {summary.get('total_pageviews')} / ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆè¨ˆ: {summary.get('total_visitors')}"
        )
        if summary.get("avg_session_seconds") is not None:
            lines.append(
                f"- å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“(åŠ é‡å¹³å‡): {summary['avg_session_seconds']:.1f}ç§’"
            )
        if summary.get("bounce_rate") is not None:
            lines.append(f"- æ¨å®šç›´å¸°ç‡(åŠ é‡å¹³å‡): {summary['bounce_rate']*100:.1f}%")
    if not conversion_df.empty:
        top_sources = (
            conversion_df.sort_values("sessions", ascending=False)
            .head(5)[["traffic_category", "source", "sessions"]]
            .to_dict("records")
        )
        lines.append("- ä¸»è¦æµå…¥å…ƒ(ã‚»ãƒƒã‚·ãƒ§ãƒ³é †):")
        for src in top_sources:
            lines.append(
                f"  - {src['traffic_category']} / {src['source']}: {src['sessions']}ã‚»ãƒƒã‚·ãƒ§ãƒ³"
            )
    if not page_click_df.empty:
        top_pages = page_click_df.head(5).to_dict("records")
        lines.append("- ãƒšãƒ¼ã‚¸åˆ¥ã®ä¸»ãªã‚¯ãƒªãƒƒã‚¯çŠ¶æ³:")
        for row in top_pages:
            cr = row["click_rate_calc"] * 100 if pd.notna(row["click_rate_calc"]) else None
            lines.append(
                f"  - {row['page_path']}: è¨ªå• {row['visitors']} / ã‚¯ãƒªãƒƒã‚¯ {row['clicks']} / ã‚¯ãƒªãƒƒã‚¯ç‡ {cr:.1f}%"
            )
    if extra_context.strip():
        lines.append(f"- è£œè¶³æƒ…å ±: {extra_context.strip()}")
    lines.append(
        "æµå…¥æ”¹å–„ã€CVRå‘ä¸Šã€ç›´å¸°ç‡ä½æ¸›ã«ã¤ãªãŒã‚‹å…·ä½“çš„ãªæ–½ç­–ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚å„æ–½ç­–ã«ã¯ç†ç”±ã‚’ä¸€è¨€æ·»ãˆã¦ãã ã•ã„ã€‚"
    )
    return "\n".join(lines)


def call_openai_deep_research(
    api_key: str, model: str, prompt: str, max_tokens: int = 2000
) -> str:
    """
    Deep Research APIå‘ã‘ã¨ã—ã¦ã„ãŸãŒã€ã“ã“ã§ã¯æ±ç”¨ã®GPT-5ç³»(chat.completions)ã§
    è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚max_tokensã¯ãƒ¢ãƒ‡ãƒ«ã®åˆ¶ç´„ã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
    """
    client = OpenAI(api_key=api_key)
    messages = [
        {
            "role": "system",
            "content": "ã‚ãªãŸã¯å¸‚å ´èª¿æŸ»ã¨LPæœ€é©åŒ–ã«é•·ã‘ãŸãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã§ã™ã€‚æƒ…å ±é‡å¤šã‚ã§å…·ä½“çš„ãªæ—¥æœ¬èªãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownã§è¿”ã—ã¦ãã ã•ã„ã€‚",
        },
        {"role": "user", "content": prompt},
    ]
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.5,
            max_completion_tokens=max_tokens,
        )
    except Exception as exc:
        msg = str(exc).lower()
        if "max_completion_tokens" in msg:
            # max_completion_tokens æœªå¯¾å¿œãƒ¢ãƒ‡ãƒ«ãªã‚‰ã€ãƒˆãƒ¼ã‚¯ãƒ³æŒ‡å®šãªã—ã§å†è©¦è¡Œ
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.5,
            )
        elif "max_tokens" in msg:
            # max_tokens æœªå¯¾å¿œ(= max_completion_tokens å¿…é ˆ)ãªã‚‰ã€å†åº¦ max_completion_tokens ã§è©¦è¡Œ
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.5,
                max_completion_tokens=max_tokens,
            )
        else:
            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯ãã®ã¾ã¾ä¸Šã’ã‚‹
            raise
    return response.choices[0].message.content


def build_report_prompt(
    summary: dict,
    conversion_df: pd.DataFrame,
    page_click_df: pd.DataFrame,
    goal_text: str,
) -> str:
    lines = [
        "ã‚ãªãŸã¯LPæœ€é©åŒ–ã¨CROã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ­ã‚°è¦ç´„ã‚’åŸºã«ã€A4 1æšç¨‹åº¦ã®æ—¥æœ¬èªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
        "èª­è€…ã¯ãƒãƒ¼ã‚±/äº‹æ¥­è²¬ä»»è€…ã‚’æƒ³å®šã—ã€ç®‡æ¡æ›¸ãä¸­å¿ƒã ãŒæƒ…å ±é‡å¤šã‚ã§ã€æ•°å­—ã¨ä»®èª¬ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚",
        "",
        "å¿…é ˆæ§‹æˆ:",
        "1) æœŸé–“ã‚µãƒãƒªãƒ¼ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³/ PV / UU / å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“ / ç›´å¸°ç‡ï¼‰",
        "2) ãƒšãƒ¼ã‚¸ã”ã¨ã®ç°¡æ˜“é›†è¨ˆï¼ˆè¨ªå•æ•°ãƒ»å¹³å‡æ»åœ¨æ™‚é–“ãƒ»ã‚¯ãƒªãƒƒã‚¯æ•°ã®å‚¾å‘ã€‚ä¸»è¦ãƒšãƒ¼ã‚¸ã‚’åˆ—æŒ™ï¼‰",
        "3) ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•ã®ç‰¹å¾´ï¼ˆã‚ˆãè¦‹ã‚‰ã‚Œã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ç›´å¸°ãŒå¤šãã†ãªãƒšãƒ¼ã‚¸ãªã©ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼‰",
        "4) æµå…¥ã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼ˆä¸»è¦æµå…¥å…ƒã®ã‚·ã‚§ã‚¢ã¨è³ªã®ä»®èª¬ã€æ”¹å–„ä½™åœ°ï¼‰",
        "5) LPæ”¹å–„ã«ã¤ãªãŒã‚‹ç¤ºå”†ãƒ»æ–½ç­–æ¡ˆï¼ˆ3ã€œ5ç‚¹ã€å„ªå…ˆåº¦ãƒ»ç†ç”±ãƒ»æœŸå¾…åŠ¹æœãƒ»å¿…è¦ãªã‚¢ã‚»ãƒƒãƒˆ/æ”¹ä¿®ãƒ»ç°¡æ˜“å®Ÿè£…æ¡ˆï¼‰",
        "6) è¨ˆæ¸¬ã¨å®Ÿé¨“ã‚¢ã‚¤ãƒ‡ã‚¢ï¼ˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°è¿½åŠ ã€A/Bæ¡ˆã€ä¸»è¦KPIã¨å‰¯æŒ‡æ¨™ï¼‰",
        "ç´™é¢ã¯A4 1æšç›¸å½“ã§ã€ç®‡æ¡æ›¸ãã‚’ä¸»ä½“ã«ã—ã¤ã¤å…·ä½“çš„ã«ã€‚å¿…ãšæ•°å­—ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚",
    ]
    if goal_text.strip():
        lines.append(f"- LPã®ã‚´ãƒ¼ãƒ«/è£œè¶³: {goal_text.strip()}")
    if summary:
        lines.append(
            f"- æœŸé–“ã‚µãƒãƒªãƒ¼: ã‚»ãƒƒã‚·ãƒ§ãƒ³ {summary.get('total_sessions')} / PV {summary.get('total_pageviews')} / UU {summary.get('total_visitors')} / å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³ {format_seconds(summary.get('avg_session_seconds'))} / ç›´å¸°ç‡ {summary.get('bounce_rate')*100:.1f}%"
            if summary.get("bounce_rate") is not None
            else f"- æœŸé–“ã‚µãƒãƒªãƒ¼: ã‚»ãƒƒã‚·ãƒ§ãƒ³ {summary.get('total_sessions')} / PV {summary.get('total_pageviews')} / UU {summary.get('total_visitors')}"
        )
    if not conversion_df.empty:
        top_sources = (
            conversion_df.sort_values("sessions", ascending=False)
            .head(5)[["traffic_category", "source", "sessions"]]
            .to_dict("records")
        )
        lines.append("- æµå…¥ä¸Šä½ (ã‚»ãƒƒã‚·ãƒ§ãƒ³é †): " + "; ".join([f"{r['traffic_category']} / {r['source']} : {r['sessions']}" for r in top_sources]))
    if not page_click_df.empty:
        top_pages = page_click_df.head(5).to_dict("records")
        lines.append("- ã‚¯ãƒªãƒƒã‚¯ä¸Šä½ãƒšãƒ¼ã‚¸: " + "; ".join([f"{r['page_path']} (è¨ªå• {r['visitors']}, ã‚¯ãƒªãƒƒã‚¯ {r['clicks']})" for r in top_pages]))
    lines.append("A4 1ãƒšãƒ¼ã‚¸ã«åã¾ã‚‹ã‚ˆã†ã«ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚")
    return "\n".join(lines)


def main() -> None:
    inject_styles()
    st.markdown('<div style="height:12px;"></div>', unsafe_allow_html=True)

    st.markdown(
        """
        <div class="hero">
            <div class="hero-title">LPè¡Œå‹•ãƒ­ã‚°ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼</div>
            <div style="margin-top:6px;">
                <span class="badge">Streamlit</span>
                <span class="badge">Altair</span>
                <span class="badge">OpenAI</span>
            </div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    with st.sidebar:
        st.header("è¨­å®š")
        model = st.text_input("ãƒ¢ãƒ‡ãƒ«å", value=DEFAULT_MODEL)
        secret_hint = st.secrets.get("openai_api_key") or st.secrets.get("OPENAI_API_KEY")
        if secret_hint:
            st.success("secrets.toml ã® openai_api_key ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
        else:
            st.warning("secrets.toml ã« openai_api_key ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã™ã‚‹ã¨æ”¹å–„æ¡ˆãŒç”Ÿæˆã§ãã¾ã™ã€‚")
        goal_text = st.text_area("ãƒ­ã‚°è§£æç›®çš„", value="æ¡ç”¨ã®å¿œå‹Ÿç‡ã‚’æ”¹å–„ã—ãŸã„")
        st.divider()
        st.subheader("ãƒ‡ãƒ¼ã‚¿å·®ã—æ›¿ãˆ")
        traffic_upload = st.file_uploader("ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆ CSV", type=["csv"])
        conversion_upload = st.file_uploader("æµå…¥å…ƒãƒ¬ãƒãƒ¼ãƒˆ CSV", type=["csv"])
        clicks_upload = st.file_uploader("ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ CSV", type=["csv"])
        st.caption("æœªæŒ‡å®šæ™‚ã¯ datas/ é…ä¸‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚")

    api_key = get_api_key()

    raw_traffic = load_csv(traffic_upload, "ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆ_2025-11-06-2025-12-06.csv")
    raw_conversion = load_csv(conversion_upload, "conversion_table_api_2025-11-06-2025-12-06.csv")
    raw_clicks = load_csv(clicks_upload, "button_clicks_table_api_2025-11-06-2025-12-06.csv")

    traffic_df = clean_traffic(raw_traffic)
    conversion_df = clean_conversion(raw_conversion)
    clicks_df = clean_clicks(raw_clicks)
    page_click_summary = build_page_click_summary(clicks_df)

    date_min = traffic_df["date"].min().date() if not traffic_df.empty else None
    date_max = traffic_df["date"].max().date() if not traffic_df.empty else None
    with st.expander("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", expanded=True):
        colf1, colf2, colf3, colf4 = st.columns(4)
        if date_min and date_max:
            date_range = colf1.date_input(
                "åˆ†ææœŸé–“",
                (date_min, date_max),
                min_value=date_min,
                max_value=date_max,
            )
        else:
            date_range = ()
        page_keyword = colf2.text_input("ãƒšãƒ¼ã‚¸ãƒ‘ã‚¹ã§çµã‚Šè¾¼ã¿", placeholder="/project, /company ...")
        max_vis = int(page_click_summary["visitors"].max()) if not page_click_summary.empty else 100
        max_vis = max(max_vis, 50)
        min_visitors = colf3.slider("è¨ªå•æ•°ã®ä¸‹é™ (CTAé›†è¨ˆ)", 0, max_vis, min(50, max_vis), step=10)
        top_n = colf4.slider("å¯è¦–åŒ–ã™ã‚‹ä¸Šä½ä»¶æ•°", 5, 50, 15, step=5)

        traffic_view = traffic_df.copy()
        if isinstance(date_range, tuple) and len(date_range) == 2 and date_range[0] and date_range[1]:
            start, end = date_range
            traffic_view = traffic_view[
                (traffic_view["date"].dt.date >= start) & (traffic_view["date"].dt.date <= end)
            ]
        clicks_view = page_click_summary.copy()
        if page_keyword:
            key = page_keyword.lower()
            clicks_view = clicks_view[clicks_view["page_path"].str.lower().str.contains(key)]
        clicks_view = clicks_view[clicks_view["visitors"] >= min_visitors]
        clicks_for_chart = clicks_view.head(top_n)

        summary = summarize_traffic(traffic_view)

        metric_cards = [
            {
                "label": "ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆè¨ˆ",
                "value": f"{summary.get('total_sessions', 0):,}",
                "desc": "æœŸé–“å†…ã®ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³",
            },
            {
                "label": "ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼åˆè¨ˆ",
                "value": f"{summary.get('total_pageviews', 0):,}",
                "desc": "é–²è¦§ãƒšãƒ¼ã‚¸ç·æ•°",
            },
            {
                "label": "è¨ªå•ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆè¨ˆ",
                "value": f"{summary.get('total_visitors', 0):,}",
                "desc": "ãƒ¦ãƒ‹ãƒ¼ã‚¯è¨ªå•",
            },
            {
                "label": "å¹³å‡ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“",
                "value": format_seconds(summary.get("avg_session_seconds")),
                "desc": "åŠ é‡å¹³å‡",
            },
        ]
        bounce_rate = summary.get("bounce_rate")
        if bounce_rate is not None:
            metric_cards.append(
                {
                    "label": "æ¨å®šç›´å¸°ç‡",
                    "value": f"{bounce_rate*100:.1f}%",
                    "desc": "æœŸé–“åŠ é‡å¹³å‡",
                }
            )
        cards_html = '<div class="metric-grid">' + "".join(
            [
                f"<div class='metric-card'><div class='metric-title'>{c['label']}</div>"
                f"<div class='metric-value'>{c['value']}</div>"
                f"<div class='metric-desc'>{c['desc']}</div></div>"
                for c in metric_cards
            ]
        ) + "</div>"
        st.markdown(cards_html, unsafe_allow_html=True)

    tabs = st.tabs(
        ["æ¦‚è¦", "è¡Œå‹•/CTA", "æµå…¥å…ƒ", "æ”¹å–„æ¡ˆ (AI)", "ç”Ÿãƒ‡ãƒ¼ã‚¿", "LPãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"]
    )

    with tabs[0]:
        st.subheader("ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ")
        highlights = behavioral_highlights(traffic_view, clicks_view)
        if highlights:
            st.write("è¡Œå‹•ç‰¹å¾´")
            for txt in highlights:
                st.write(f"- {txt}")
        else:
            st.info("ç‰¹å¾´ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒè¶³ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        col_a, col_b = st.columns(2)
        if not clicks_view.empty:
            col_a.write("ã‚¯ãƒªãƒƒã‚¯ãŒå¤šã„ãƒšãƒ¼ã‚¸ (ä¸Šä½5)")
            top_pages = clicks_view.head(5)[["page_path", "visitors", "clicks", "click_rate_calc"]]
            col_a.dataframe(
                top_pages.rename(
                    columns={
                        "page_path": "ãƒšãƒ¼ã‚¸",
                        "visitors": "è¨ªå•",
                        "clicks": "ã‚¯ãƒªãƒƒã‚¯",
                        "click_rate_calc": "ã‚¯ãƒªãƒƒã‚¯ç‡",
                    }
                ),
                use_container_width=True,
            )
            col_b.write("ã‚¯ãƒªãƒƒã‚¯ç‡ãŒä½ã„ãƒšãƒ¼ã‚¸ (è¨ªå•æ•°ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨)")
            low_pages = (
                clicks_view.sort_values("click_rate_calc", ascending=True)
                .head(5)[["page_path", "visitors", "clicks", "click_rate_calc"]]
            )
            col_b.dataframe(
                low_pages.rename(
                    columns={
                        "page_path": "ãƒšãƒ¼ã‚¸",
                        "visitors": "è¨ªå•",
                        "clicks": "ã‚¯ãƒªãƒƒã‚¯",
                        "click_rate_calc": "ã‚¯ãƒªãƒƒã‚¯ç‡",
                    }
                ),
                use_container_width=True,
            )
        else:
            st.info("ã‚¯ãƒªãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    with tabs[1]:
        st.subheader("è¡Œå‹•ãƒˆãƒ¬ãƒ³ãƒ‰")
        if traffic_view.empty:
            st.warning("ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            trend_df = traffic_view[["date", "pageviews", "sessions", "unique_visitors"]]
            melt = trend_df.melt("date", var_name="metric", value_name="value")
            chart = tune_chart(
                alt.Chart(melt)
                .mark_line(point=True)
                .encode(
                    x=alt.X("date:T", title="æ—¥ä»˜"),
                    y=alt.Y("value:Q", title="ä»¶æ•°"),
                    color=alt.Color("metric:N", title="æŒ‡æ¨™"),
                    tooltip=["date:T", "metric:N", "value:Q"],
                )
                .properties(height=320)
            )
            st.altair_chart(chart, use_container_width=True)

            engagement = traffic_view[["date", "avg_session_seconds", "bounce_rate"]].melt(
                "date", var_name="metric", value_name="value"
            )
            engagement["value_display"] = engagement.apply(
                lambda r: r["value"] * 100 if r["metric"] == "bounce_rate" else r["value"],
                axis=1,
            )
            engagement_chart = tune_chart(
                alt.Chart(engagement)
                .mark_line(point=True)
                .encode(
                    x=alt.X("date:T", title="æ—¥ä»˜"),
                    y=alt.Y("value_display:Q", title="å€¤"),
                    color=alt.Color("metric:N", title="æŒ‡æ¨™"),
                    tooltip=["date:T", "metric:N", "value_display:Q"],
                )
                .properties(height=260)
            )
            st.caption("æ»åœ¨æ™‚é–“ã¯ç§’ã€ç›´å¸°ç‡ã¯%ã¨ã—ã¦è¡¨ç¤º")
            st.altair_chart(engagement_chart, use_container_width=True)

        st.subheader("CTA / ã‚¯ãƒªãƒƒã‚¯åˆ†å¸ƒ")
        if clicks_for_chart.empty:
            st.warning("CTAãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        else:
            scatter = tune_chart(
                alt.Chart(clicks_for_chart)
                .mark_circle(size=120)
                .encode(
                    x=alt.X("visitors:Q", title="è¨ªå•æ•°"),
                    y=alt.Y("click_rate_calc:Q", title="ã‚¯ãƒªãƒƒã‚¯ç‡", axis=alt.Axis(format=".0%")),
                    size=alt.Size("clicks:Q", title="ã‚¯ãƒªãƒƒã‚¯æ•°"),
                    color=alt.Color("click_rate_calc:Q", title="ã‚¯ãƒªãƒƒã‚¯ç‡", scale=alt.Scale(scheme="blues")),
                    tooltip=[
                        "page_path",
                        "visitors",
                        "clicks",
                        alt.Tooltip("click_rate_calc:Q", title="ã‚¯ãƒªãƒƒã‚¯ç‡", format=".1%"),
                    ],
                )
                .properties(height=320)
            )
            st.altair_chart(scatter, use_container_width=True)
            st.dataframe(
                clicks_view[
                    ["page_path", "visitors", "clicks", "click_rate_calc", "avg_click_rate"]
                ].rename(
                    columns={
                        "page_path": "ãƒšãƒ¼ã‚¸",
                        "visitors": "è¨ªå•æ•°",
                        "clicks": "ã‚¯ãƒªãƒƒã‚¯æ•°",
                        "click_rate_calc": "ã‚¯ãƒªãƒƒã‚¯ç‡(ç®—å‡º)",
                        "avg_click_rate": "ã‚¯ãƒªãƒƒã‚¯ç‡(å¹³å‡)",
                    }
                ),
                use_container_width=True,
                height=420,
            )

    with tabs[2]:
        st.subheader("æµå…¥å…ƒ")
        if conversion_df.empty:
            st.warning("æµå…¥å…ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            conv = conversion_df.copy()
            conv["session_share"] = conv["sessions"] / conv["sessions"].sum()
            top_conv = conv.sort_values("sessions", ascending=False).head(12)
            conv_chart = tune_chart(
                alt.Chart(top_conv)
                .mark_bar(cornerRadiusTopLeft=4, cornerRadiusTopRight=4)
                .encode(
                    x=alt.X("sessions:Q", title="ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°"),
                    y=alt.Y("source:N", sort="-x", title="æµå…¥å…ƒ"),
                    color=alt.Color("traffic_category:N", title="ã‚«ãƒ†ã‚´ãƒªãƒ¼"),
                    tooltip=[
                        "traffic_category",
                        "source",
                        "sessions",
                        "unique_visitors",
                        alt.Tooltip("session_share:Q", format=".1%", title="ã‚·ã‚§ã‚¢"),
                    ],
                )
                .properties(height=360)
            )
            st.altair_chart(conv_chart, use_container_width=True)
            st.dataframe(
                top_conv[
                    ["traffic_category", "source", "sessions", "pageviews", "unique_visitors", "session_share"]
                ].rename(
                    columns={
                        "traffic_category": "ã‚«ãƒ†ã‚´ãƒª",
                        "source": "ã‚½ãƒ¼ã‚¹",
                        "sessions": "ã‚»ãƒƒã‚·ãƒ§ãƒ³",
                        "pageviews": "PV",
                        "unique_visitors": "è¨ªå•è€…",
                        "session_share": "ã‚·ã‚§ã‚¢",
                    }
                ),
                use_container_width=True,
                height=400,
            )

    with tabs[3]:
        st.subheader("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ (OpenAI)")
        st.markdown("GPT-5ç³»ãƒ¢ãƒ‡ãƒ«ã§A4 1ãƒšãƒ¼ã‚¸ç›¸å½“ã®è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
        report_model = st.text_input("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«", value=DEFAULT_MODEL)
        if "report_md" not in st.session_state:
            st.session_state.report_md = ""
        if "report_pdf" not in st.session_state:
            st.session_state.report_pdf = None
        if "report_html" not in st.session_state:
            st.session_state.report_html = ""

        if api_key:
            if st.button("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ (1ãƒšãƒ¼ã‚¸)", type="primary"):
                report_prompt = build_report_prompt(
                    summary, conversion_df, clicks_view, goal_text or ""
                )
                with st.spinner("GPT-5ç³»ãƒ¢ãƒ‡ãƒ«ã§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­..."):
                    try:
                        md = call_openai_deep_research(
                            api_key, report_model or model, report_prompt
                        )
                        st.session_state.report_md = md
                        html = markdown_to_html(md)
                        st.session_state.report_html = html
                        st.session_state.report_pdf = html_to_pdf_bytes(html)
                        st.success("ãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    except Exception as exc:
                        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼: {exc}")

            if st.session_state.report_md:
                st.markdown("##### ãƒ¬ãƒãƒ¼ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.text(st.session_state.report_md)
                # if st.session_state.report_pdf:
                #     st.download_button(
                #         "PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                #         data=st.session_state.report_pdf,
                #         file_name="lp_report.pdf",
                #         mime="application/pdf",
                #     )
                # else:
                #     st.info(
                #         "PDFç”Ÿæˆã«ã¯ weasyprint ãŒå¿…è¦ã§ã™ã€‚`pip install weasyprint` ã‚’å®Ÿè¡Œå¾Œã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
                #     )
        else:
            st.info("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«ã¯ OpenAI API Key (.streamlit/secrets.toml) ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    with tabs[4]:
        st.subheader("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª")
        st.write("ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚µãƒãƒª")
        st.dataframe(traffic_df, use_container_width=True)
        st.write("æµå…¥å…ƒãƒ‡ãƒ¼ã‚¿")
        st.dataframe(conversion_df, use_container_width=True)
        st.write("ã‚¯ãƒªãƒƒã‚¯ãƒ­ã‚°")
        st.dataframe(clicks_df, use_container_width=True, height=320)

    with tabs[5]:
        st.subheader("LPãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (iframe)")
        st.caption(
            "X-Frame-Options ã‚„ CSP ã§ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã€‚ãã®éš›ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã§ç›´æ¥é–‹ã„ã¦ãã ã•ã„ã€‚"
        )
        lp_url = st.text_input("URL", value=DEFAULT_LP_URL)
        height = st.slider("é«˜ã•(px)", 400, 1400, 900, step=50)
        if lp_url:
            try:
                st.components.v1.iframe(lp_url, height=height, scrolling=True)
            except Exception as exc:
                st.error(f"iframe åŸ‹ã‚è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")


if __name__ == "__main__":
    main()
